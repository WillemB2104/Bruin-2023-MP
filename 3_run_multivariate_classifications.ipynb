{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import sklearn as sk\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from time import time\n",
    "import json\n",
    "from itertools import product\n",
    "import datetime\n",
    "\n",
    "from scripts.ComBat_experiments import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import re, string\n",
    "from scripts.evaluation_classifier import Evaluater\n",
    "from scripts.pycombat import Combat\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, cross_val_predict, RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, KernelCenterer, LabelEncoder, label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, jaccard_score\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from nilearn import plotting\n",
    "\n",
    "from nilearn.maskers import NiftiLabelsMasker, NiftiMasker\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce090867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__ # '1.0.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fe62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_filelist(filelist, feature_label, file_filter=[]):\n",
    "    filter_list = np.append(feature_label.lower(), file_filter)\n",
    "    if 'seedCorr' in feature_label:\n",
    "        mask = [np.all([f in file.split('task-')[-1].lower() for f in filter_list]) for file in rename_seed_files(filelist)]\n",
    "    else:\n",
    "        mask = [np.all([f in file.split('task-')[-1].lower() for f in filter_list]) for file in filelist]\n",
    "    return sorted(np.array(filelist)[mask])\n",
    "\n",
    "\n",
    "\n",
    "def repeated_group_stratified_KFold_splits(y, groups, n_folds=5, n_repeats=20, seed=0, verbose=True):\n",
    "    \n",
    "    # Combine class and site labels\n",
    "    labels_to_strat = np.array([site + \"_and_\" + str(int(label)) for site, label in zip(groups, y)])\n",
    "    \n",
    "    # Check if there are any site * label combinations with less than 2 counts\n",
    "    vals, counts = np.unique(labels_to_strat, return_counts=True)\n",
    "    vals_to_filter = vals[counts < 2]\n",
    "    \n",
    "    # Stratify these only by site instead\n",
    "    if len(vals_to_filter) > 0:\n",
    "        if verbose:\n",
    "            print(\"Warning! Detected site * label combinations with less than 2 counts:\")\n",
    "            print(f\"{vals[counts < 2]} : {counts[counts < 2]}\")\n",
    "        for val in vals_to_filter:\n",
    "            new_val = val.split('_and_')[0] + '_and_' + str(int(not bool(int(val.split('_and_')[1]))))\n",
    "            labels_to_strat[labels_to_strat == val] = new_val\n",
    "            if verbose:\n",
    "                print(f\"Replaced {val} with {new_val}\")\n",
    "        \n",
    "    # Create and return repeated group stratified KFold splits\n",
    "    cv_splits = []\n",
    "    ssKFold_cv = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=seed)\n",
    "    for i, (train, test) in enumerate(ssKFold_cv.split(y=labels_to_strat, X=np.zeros_like(labels_to_strat))):\n",
    "        cv_splits.append((train, test))\n",
    "    return(cv_splits)\n",
    "\n",
    "\n",
    "\n",
    "def group_stratified_shuffle_cv_splits(y, groups, n_splits=100, train_size=0.8, test_size=0.2, seed=0, \n",
    "                                       verbose=True):\n",
    "    \n",
    "    # Combine class and site labels\n",
    "    labels_to_strat = np.array([site + \"_and_\" + str(int(label)) for site, label in zip(groups, y)])\n",
    "    \n",
    "    # Check if there are any site * label combinations with less than 2 counts\n",
    "    vals, counts = np.unique(labels_to_strat, return_counts=True)\n",
    "    vals_to_filter = vals[counts < 2]\n",
    "    \n",
    "    # Stratify these only by site instead\n",
    "    if len(vals_to_filter) > 0:\n",
    "        if verbose:\n",
    "            print(\"Warning! Detected site * label combinations with less than 2 counts:\")\n",
    "            print(f\"{vals[counts < 2]} : {counts[counts < 2]}\")\n",
    "        for val in vals_to_filter:\n",
    "            new_val = val.split('_and_')[0] + '_and_' + str(int(not bool(int(val.split('_and_')[1]))))\n",
    "            labels_to_strat[labels_to_strat == val] = new_val\n",
    "            if verbose:\n",
    "                print(f\"Replaced {val} with {new_val}\")\n",
    "        \n",
    "    # Create and return stratified splits\n",
    "    cv_splits = []\n",
    "    ss_cv = StratifiedShuffleSplit(n_splits=n_splits, train_size=train_size, test_size=test_size, \n",
    "                                   random_state=seed)\n",
    "    for i, (train, test) in enumerate(ss_cv.split(y=labels_to_strat, X=np.zeros_like(labels_to_strat))):\n",
    "        cv_splits.append((train, test))\n",
    "    return(cv_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7d1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bool_masks(*masks):\n",
    "    return np.array([all(tup) for tup in zip(*masks)])\n",
    "\n",
    "\n",
    "def has_N_samples_per_class(covariates_df, class_label, subject_mask=None, N_threshold=10, verbose=True):\n",
    "    \n",
    "    groups = np.array(covariates_df.site_id.values)\n",
    "    \n",
    "    if subject_mask is not None:\n",
    "        tmp_df = covariates_df.loc[subject_mask, ['ID', class_label, 'Age', 'Sex', 'site_id']]\n",
    "    else:\n",
    "        tmp_df = covariates_df.loc[:, ['ID', class_label, 'Age', 'Sex', 'site_id']]\n",
    "    \n",
    "    all_sites = np.unique(tmp_df.site_id)\n",
    "    unique_class_values = sorted(np.unique(tmp_df[class_label]))\n",
    "    assert len(unique_class_values) == 2\n",
    "\n",
    "    # Store number of included subjects per class and site in Dataframe\n",
    "    counts_df = tmp_df.groupby(['site_id', class_label]).size()\n",
    "    counts_df = pd.DataFrame(counts_df)\n",
    "    counts_df = counts_df.reset_index()\n",
    "    counts_df = counts_df.pivot(index='site_id', columns=class_label)\n",
    "    counts_df.columns = counts_df.columns.droplevel(0)\n",
    "    counts_df.columns.name = None\n",
    "    counts_df = counts_df.reset_index()\n",
    "\n",
    "    included_sites = counts_df.loc[(counts_df[unique_class_values[0]] >= N_threshold) & \n",
    "                                   (counts_df[unique_class_values[1]] >= N_threshold)]['site_id'].values\n",
    "    excluded_sites = list(set(all_sites).difference(included_sites))\n",
    "    \n",
    "    counts_df = counts_df.loc[counts_df.site_id.isin(included_sites)]\n",
    "\n",
    "    site_mask = [g not in excluded_sites for g in groups]\n",
    "    \n",
    "    if verbose:\n",
    "        N_excluded = len(tmp_df.loc[tmp_df.site_id.isin(excluded_sites)])\n",
    "        print(\"Excluded {} subjects belonging to {} different sites:\\n\\n{}\".format(N_excluded, \n",
    "                                                                                   len(excluded_sites), \n",
    "                                                                                   '\\n'.join(excluded_sites)))\n",
    "    return site_mask, counts_df\n",
    "    \n",
    "\n",
    "def ensure_folder(folder_dir):\n",
    "    if not os.path.exists(folder_dir):\n",
    "        os.makedirs(folder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbaeabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_OUTPUT_DIR = '/data/wbbruin/Desktop/ENIGMA_HALFPIPE_OUTPUTS/'\n",
    "ENIGMA_ATLASES_DIR = '/data/wbbruin/Desktop/ME_RSFMRI_TEDANA/atlases_and_seeds/'\n",
    "\n",
    "FEATURE_LABELS = ['corrMatrix', 'fALFF', 'seedCorr', 'dualReg', 'reHo']\n",
    "\n",
    "# Specify directory to store group summary of halfpipe derivties (csv) and parsed features into  NumPy .npy format\n",
    "SAVE_DIR = '/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/Data/'\n",
    "\n",
    "# Regex to remove all non-alphanumeric characters\n",
    "pattern = re.compile('[\\W_]+')\n",
    "\n",
    "# Extract the 55 seed labels, reformat these to lowercase and remove all non-alphanumeric characters\n",
    "SEED_PATHS = sorted(glob(os.path.join(ENIGMA_ATLASES_DIR, '*seed_2009*')))\n",
    "assert len(SEED_PATHS) == 55 \n",
    "SEED_LABELS = [pattern.sub('', os.path.basename(seed).split('_seed_2009')[0].lower()) \n",
    "               for seed in SEED_PATHS]\n",
    "assert len(SEED_LABELS) == len(np.unique(SEED_LABELS))\n",
    "sorted_idx = np.argsort(SEED_LABELS)\n",
    "SEED_PATHS = np.array(SEED_PATHS)[sorted_idx]\n",
    "SEED_LABELS = np.array(SEED_LABELS)[sorted_idx]\n",
    "\n",
    "# Extract the 3 atlas labels for connectomes\n",
    "CONNECTOME_PATHS = sorted(glob(os.path.join(ENIGMA_ATLASES_DIR, 'tpl-MNI152NLin2009cAsym_atlas-*.nii.gz')))\n",
    "assert len(CONNECTOME_PATHS) == 3\n",
    "CONNECTOME_LABELS = [pattern.sub('', os.path.basename(atlas).split('atlas-')[-1].split('.nii.gz')[0].lower()) \n",
    "                     for atlas in CONNECTOME_PATHS]\n",
    "CONNECTOME_LABELS = [c.split('dseg')[0] for c in CONNECTOME_LABELS]\n",
    "\n",
    "sorted_idx = np.argsort(CONNECTOME_LABELS)\n",
    "CONNECTOME_PATHS = np.array(CONNECTOME_PATHS)[sorted_idx]\n",
    "CONNECTOME_LABELS = np.array(CONNECTOME_LABELS)[sorted_idx]\n",
    "\n",
    "\n",
    "# Extract the 14 dual regression component labels\n",
    "DUAL_REGRESSION_IC_LABELS = [str.lower('FINDIca_component-'+str(i).zfill(2)) for i in np.arange(14) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6694b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading most recent pooled data...\n",
      "Found data stored @ 01_03_2022\n",
      "Loaded pooled data for 2148 subjects from 33 sites...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# !!! Load most recent pooled data\n",
    "\n",
    "pooled_data_main_dir = '/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/Pooled_Data'\n",
    "pooled_data_dirs = os.listdir('/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/Pooled_Data')\n",
    "\n",
    "if len(pooled_data_dirs) > 0:\n",
    "    \n",
    "    print(\"Loading most recent pooled data...\")\n",
    "    most_recent_idx = np.argmax([datetime.datetime.strptime(d, \"%d_%m_%Y\") for d in pooled_data_dirs])\n",
    "    print(\"Found data stored @ {}\".format(pooled_data_dirs[most_recent_idx]))\n",
    "    pooled_data_dir = os.path.join(pooled_data_main_dir, pooled_data_dirs[most_recent_idx])\n",
    "    pooled_data_path = os.path.join(pooled_data_dir, 'pooled_data.npz')\n",
    "    \n",
    "    data = np.load(pooled_data_path, allow_pickle=True)\n",
    "\n",
    "    included_subject_ids=data['included_subject_ids']\n",
    "    \n",
    "    roi_labels=data['roi_labels']\n",
    "    network_labels=data['network_labels']\n",
    "    \n",
    "    network_ordering_dict=data['network_ordering_dict'].item()\n",
    "\n",
    "    fALFF_per_ROI=data['fALFF_per_ROI']\n",
    "    fALFF_per_network=data['fALFF_per_network']\n",
    "\n",
    "    reHo_per_ROI=data['reHo_per_ROI']\n",
    "    reHo_per_network=data['reHo_per_network']\n",
    "\n",
    "    CC_matrix=data['CC_matrix']\n",
    "\n",
    "    within_network_correlations=data['within_network_correlations']\n",
    "    within_network_correlations_labels=data['within_network_correlations_labels']\n",
    "\n",
    "    between_network_correlations=data['between_network_correlations']\n",
    "    between_network_correlations_labels=data['between_network_correlations_labels']\n",
    "\n",
    "    filtered_atlas_img = nib.load(os.path.join(pooled_data_dir, 'included_regions_atlas.nii.gz'))\n",
    "    lut_df = pd.read_csv(os.path.join(pooled_data_dir, 'Schaefer2018_400Parcels_17Networks_LUT.csv'))\n",
    "\n",
    "    included_subjects_derivates_df = pd.read_csv(os.path.join(pooled_data_dir, \n",
    "                                                              'included_subjects_derivates.csv'))\n",
    "    included_subjects_covariates_df = pd.read_csv(os.path.join(pooled_data_dir, \n",
    "                                                               'included_subjects_covariates.csv'))\n",
    "\n",
    "    N_subjects = included_subjects_derivates_df.shape[0]\n",
    "    N_sites = len(included_subjects_derivates_df.site_id.unique())\n",
    "\n",
    "    print(\"Loaded pooled data for {} subjects from {} sites...\".format(N_subjects, N_sites))\n",
    "\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a51777",
   "metadata": {},
   "source": [
    "### Prepare features for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01d5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n"
     ]
    }
   ],
   "source": [
    "n_ROIs = len(roi_labels)\n",
    "\n",
    "assert n_ROIs == CC_matrix.shape[-1]\n",
    "\n",
    "print(n_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce52cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "unique_network_labels = []\n",
    "\n",
    "for label in network_ordering_dict.keys():\n",
    "    if label not in network_labels:\n",
    "        continue\n",
    "    else:\n",
    "        unique_network_labels.append(label)\n",
    "        \n",
    "N_networks = len(unique_network_labels)\n",
    "\n",
    "assert N_networks == len(np.unique(network_labels))\n",
    "assert N_networks == reHo_per_network.shape[-1]\n",
    "assert N_networks == fALFF_per_network.shape[-1]\n",
    "\n",
    "print(N_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8302b2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50403.0\n",
      "50403\n",
      "(2148, 50403)\n"
     ]
    }
   ],
   "source": [
    "# Unravel pair-wise ROI-to-ROI FC as 1d features.\n",
    "\n",
    "# For a matrix of size n x n, the number of elements in the lower triangle is\n",
    "print(CC_matrix.shape[-1] * (CC_matrix.shape[-1] - 1) / 2)\n",
    "\n",
    "# Create mask for lower triangular of corremation matrix. Skip diagonal (auto) correlations.\n",
    "tril_mask = np.tril(np.ones(CC_matrix.shape[-2:]), k=-1).astype(bool)\n",
    "print(np.sum(tril_mask))\n",
    "\n",
    "# Make sure IDs are matched so we can extract diagnosis and other covariates easily\n",
    "assert np.all(included_subjects_derivates_df.site_subject_ID.values == included_subject_ids)\n",
    "assert np.all(included_subjects_covariates_df.site_subject_ID.values == included_subject_ids)\n",
    "assert np.all(included_subjects_derivates_df.site_subject_ID.values == \n",
    "              included_subjects_covariates_df.site_subject_ID.values)\n",
    "\n",
    "# Take lower triangular of FC matrix\n",
    "pairwise_ROI_to_ROI_FC_vec = CC_matrix[..., tril_mask]\n",
    "\n",
    "print(pairwise_ROI_to_ROI_FC_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f48eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50403.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(318*317)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda7b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(included_subjects_derivates_df.site_id.values ==  included_subjects_covariates_df.site_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbc4fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 18, 18)\n",
      "(2148, 153)\n",
      "(2148, 16)\n",
      "(2148, 169)\n"
     ]
    }
   ],
   "source": [
    "# We can choose to investigate within and between network FC separately, or combined\n",
    "\n",
    "print(between_network_correlations.shape)\n",
    "\n",
    "# Unravel pair-wise between-network FC correlations as 1d features. Skip diagonal!\n",
    "tril_mask = np.tril(np.ones(between_network_correlations.shape[-2:]), k=-1).astype(bool)\n",
    "pairwise_between_network_FC_vec = between_network_correlations[..., tril_mask]\n",
    "\n",
    "print(pairwise_between_network_FC_vec.shape)\n",
    "\n",
    "# Within-network FC correlations are already 1 features\n",
    "print(within_network_correlations.shape)\n",
    "\n",
    "\n",
    "# Combine between- and within network correlation vectors\n",
    "pairwise_network_FC_vec = np.c_[pairwise_between_network_FC_vec, within_network_correlations]\n",
    "print(pairwise_network_FC_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5566c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Confirm that all subjects included so far have diagnosis status\n",
    "\n",
    "print(np.unique(included_subjects_covariates_df.Diagnosis))\n",
    "assert sum(included_subjects_covariates_df.Diagnosis.isna()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806d1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 subjects miss Sex covariate\n",
      "0 subjects miss Age covariate\n",
      "178 subjects miss Years of Education covariate\n",
      "178 subjects miss ALL covariates\n"
     ]
    }
   ],
   "source": [
    "# Extract Diagnosis status, and Sex & Age covariates\n",
    "\n",
    "# \"Diagnosis\" recoded from (OCD=1, HC=2) to (OCD=1, HC=0)\n",
    "Dx_vec = np.array(included_subjects_covariates_df.Diagnosis.replace(2, 0).values, dtype=int)\n",
    "\n",
    "# \"Sex\" recoded from (1=male, 2=female) to (1=male, 0=female)\n",
    "Sex_vec = np.array(included_subjects_covariates_df.Sex.replace(2, 0).values, dtype=int)\n",
    "\n",
    "# \"Age\" scaled by / 100\n",
    "Age_vec = np.array(included_subjects_covariates_df.Age) / 100.\n",
    "\n",
    "# \"Year of Education\" scaled by / 30 (max = 27 years)\n",
    "Edu_vec = np.array(included_subjects_covariates_df.Years_of_education) / 30.\n",
    "\n",
    "# Site IDs\n",
    "groups_vec = np.array(included_subjects_derivates_df.site_id.values)\n",
    "\n",
    "# There are subjects missing either Sex, Age, Years of Education and/or all\n",
    "IDs_missing_Sex = included_subjects_covariates_df.loc[\n",
    "                                    (included_subjects_covariates_df.Sex.isna())].site_subject_ID.values\n",
    "\n",
    "IDs_missing_Age = included_subjects_covariates_df.loc[\n",
    "                                    (included_subjects_covariates_df.Age.isna())].site_subject_ID.values\n",
    "\n",
    "IDs_missing_Edu = included_subjects_covariates_df.loc[\n",
    "                                    (included_subjects_covariates_df.Years_of_education.isna(\n",
    "                                    ))].site_subject_ID.values\n",
    "\n",
    "IDs_missing_age_and_sex_covars = set(IDs_missing_Age).union(IDs_missing_Sex)\n",
    "IDs_missing_all_covars = set(IDs_missing_Age).union(IDs_missing_Sex).union(IDs_missing_Edu)\n",
    "\n",
    "print(\"{} subjects miss Sex covariate\".format(len(IDs_missing_Sex)))\n",
    "print(\"{} subjects miss Age covariate\".format(len(IDs_missing_Age)))\n",
    "print(\"{} subjects miss Years of Education covariate\".format(len(IDs_missing_Edu)))\n",
    "print(\"{} subjects miss ALL covariates\".format(len(IDs_missing_all_covars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f28d12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "IDs_missing_FD = included_subjects_derivates_df.loc[\n",
    "                                    (included_subjects_derivates_df.fd_mean.isna(\n",
    "                                    ))].site_subject_ID.values\n",
    "\n",
    "FD_vec = np.array(included_subjects_derivates_df.fd_mean.values)\n",
    "print(IDs_missing_FD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd70985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N unmed_pt samples: 555\n",
      "N med_pt samples: 528\n",
      "N unmed_hc samples: 748\n",
      "N med_hc samples: 0\n",
      "N Med_OCD_Unmed_HC samples: 1276\n",
      "N Unmed_OCD_Unmed_HC samples: 1303\n"
     ]
    }
   ],
   "source": [
    "# Extract info for sensitivity analyses: medication status, age of onset, years of education, severity\n",
    "\n",
    "# \"Medication status at time of scan  (1=naive, 2=unmedicated, 3=medicated)\n",
    "\n",
    "is_unmed_pt = ((included_subjects_covariates_df.Medication_status.isin([1, 2])) & \n",
    "               (included_subjects_covariates_df.Diagnosis == 1))\n",
    "\n",
    "is_med_pt = ((included_subjects_covariates_df.Medication_status.isin([3])) & \n",
    "             (included_subjects_covariates_df.Diagnosis == 1))\n",
    "\n",
    "is_unmed_hc = ((included_subjects_covariates_df.Medication_status.isin([1, 2])) & \n",
    "               (included_subjects_covariates_df.Diagnosis == 2))\n",
    "\n",
    "is_med_hc = (included_subjects_covariates_df.Medication_status.isin([3]) & \n",
    "            (included_subjects_covariates_df.Diagnosis == 2))\n",
    "\n",
    "# Specific for unmedicated OCD vs HC or medicated OCD vs HC\n",
    "is_med_pt_or_unmed_hc_mask = is_med_pt | is_unmed_hc \n",
    "is_unmed_pt_or_unmed_hc_mask = is_unmed_pt | is_unmed_hc\n",
    "\n",
    "medication_groups_masks_dict = {\n",
    "                                 'unmed_pt': is_unmed_pt,\n",
    "                                 'med_pt': is_med_pt,\n",
    "                                 'unmed_hc': is_unmed_hc,\n",
    "                                 'med_hc': is_med_hc\n",
    "                                }\n",
    "\n",
    "medication_groups = list(medication_groups_masks_dict.keys())\n",
    "\n",
    "for medication_group in medication_groups:\n",
    "    print(\"N {} samples: {}\".format(medication_group, sum(medication_groups_masks_dict[medication_group])))\n",
    "    \n",
    "\n",
    "Dx_med_filter_dict = {\n",
    "                      'Med_OCD_Unmed_HC' : is_med_pt_or_unmed_hc_mask,\n",
    "                      'Unmed_OCD_Unmed_HC' : is_unmed_pt_or_unmed_hc_mask\n",
    "                      }\n",
    "\n",
    "Dx_med_filter_labels = list(Dx_med_filter_dict.keys())\n",
    "\n",
    "for Dx_med_filter in Dx_med_filter_labels:\n",
    "    print(\"N {} samples: {}\".format(Dx_med_filter, sum(Dx_med_filter_dict[Dx_med_filter])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "653819b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "N low_sev_pt samples: 579\n",
      "N high_sev_pt samples: 494\n",
      "N Low_Sev_OCD_Unmed_HC samples: 1327\n",
      "N High_Sev_OCD_Unmed_HC samples: 1242\n"
     ]
    }
   ],
   "source": [
    "# Define median severity for patients\n",
    "\n",
    "median_sev = included_subjects_covariates_df.loc[(~included_subjects_covariates_df['Y-BOCS'].isna()) &\n",
    "                                                 (included_subjects_covariates_df.Diagnosis == 1)]\\\n",
    "                                                ['Y-BOCS'].median()\n",
    "print(median_sev)\n",
    "\n",
    "\n",
    "# Previously for structural ENIGMA-OCD we defined severity splits with median 24:\n",
    "\n",
    "# (YBOCS <= 24; mild-moderate) and high severity (YBOCS > 24; moderate-severe) OCD;\n",
    "# y = np.array(y > 24, dtype=int)\n",
    "\n",
    "# Now we use YBOCS <= 25 (mild-moderate) and > 25 (moderate-severe)\n",
    "is_low_sev_pt = ((included_subjects_covariates_df['Y-BOCS'] <= median_sev) & \n",
    "                 (included_subjects_covariates_df.Diagnosis == 1))\n",
    "is_high_sev_pt = ((included_subjects_covariates_df['Y-BOCS'] > median_sev) & \n",
    "                  (included_subjects_covariates_df.Diagnosis == 1))\n",
    "\n",
    "sev_groups_masks_dict = {\n",
    "                         'low_sev_pt': is_low_sev_pt,\n",
    "                         'high_sev_pt': is_high_sev_pt\n",
    "                        }\n",
    "\n",
    "sev_groups = list(sev_groups_masks_dict.keys())\n",
    "\n",
    "for sev_group in sev_groups:\n",
    "    print(\"N {} samples: {}\".format(sev_group, sum(sev_groups_masks_dict[sev_group])))\n",
    "    \n",
    "# Only want to look into high/low sevety patients vs unmedicated subjects!\n",
    "is_low_sev_pt_or_unmed_hc_mask = is_low_sev_pt | is_unmed_hc \n",
    "is_high_sev_pt_or_unmed_hc_mask = is_high_sev_pt | is_unmed_hc\n",
    "    \n",
    "Dx_sev_filter_dict = {\n",
    "                      'Low_Sev_OCD_Unmed_HC' : is_low_sev_pt_or_unmed_hc_mask,\n",
    "                      'High_Sev_OCD_Unmed_HC' : is_high_sev_pt_or_unmed_hc_mask\n",
    "                      }\n",
    "\n",
    "Dx_sev_filter_labels = list(Dx_sev_filter_dict.keys())\n",
    "\n",
    "for Dx_sev_filter in Dx_sev_filter_labels:\n",
    "    print(\"N {} samples: {}\".format(Dx_sev_filter, sum(Dx_sev_filter_dict[Dx_sev_filter])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c04f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N early_AO_pt samples: 492\n",
      "N late_AO_pt samples: 478\n",
      "N Early_AO_OCD_Unmed_HC samples: 1240\n",
      "N Late_AO_OCD_Unmed_HC samples: 1226\n"
     ]
    }
   ],
   "source": [
    "# Define masks for early and late onset OCD:\n",
    "\n",
    "# Early-onset OCD patients / children (onset before age 18) to controls\n",
    "# Late-onset OCD patients / adult (onset at age 18 or older)\n",
    "\n",
    "# Consistent with previous ENIGMA-OCD analyses, I used y = np.array(y >= 18, dtype=int) for structural\n",
    "\n",
    "# Now we only have coding for 1 or 2 (1=Child-onset, 2=Adult-onset, N/A)\n",
    "\n",
    "is_early_AO_pt = ((included_subjects_covariates_df.Age_of_onset == 1) & \n",
    "                  (included_subjects_covariates_df.Diagnosis == 1))\n",
    "is_late_AO_pt = ((included_subjects_covariates_df.Age_of_onset == 2) & \n",
    "                 (included_subjects_covariates_df.Diagnosis == 1))\n",
    "\n",
    "AO_groups_masks_dict = {\n",
    "                        'early_AO_pt': is_early_AO_pt,\n",
    "                        'late_AO_pt': is_late_AO_pt\n",
    "                        }\n",
    "\n",
    "AO_groups = list(AO_groups_masks_dict.keys())\n",
    "\n",
    "for AO_group in AO_groups:\n",
    "    print(\"N {} samples: {}\".format(AO_group, sum(AO_groups_masks_dict[AO_group])))\n",
    "    \n",
    "    \n",
    "# Only want to look into high/low sevety patients vs unmedicated subjects!\n",
    "is_early_AO_pt_or_unmed_hc_mask = is_early_AO_pt | is_unmed_hc \n",
    "is_late_AO_pt_or_unmed_hc_mask = is_late_AO_pt | is_unmed_hc\n",
    "    \n",
    "Dx_AO_filter_dict = {\n",
    "                      'Early_AO_OCD_Unmed_HC' : is_early_AO_pt_or_unmed_hc_mask,\n",
    "                      'Late_AO_OCD_Unmed_HC' : is_late_AO_pt_or_unmed_hc_mask\n",
    "                      }\n",
    "\n",
    "Dx_AO_filter_labels = list(Dx_AO_filter_dict.keys())\n",
    "\n",
    "for Dx_AO_filter in Dx_AO_filter_labels:\n",
    "    print(\"N {} samples: {}\".format(Dx_AO_filter, sum(Dx_AO_filter_dict[Dx_AO_filter])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f2e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56723e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N pooled samples: 2148\n",
      "N adult samples: 1897\n",
      "N pediatric samples: 251\n"
     ]
    }
   ],
   "source": [
    "# Define masks for specific age groups\n",
    "is_pediatric_mask = included_subjects_covariates_df.Age_Sample_WBB.isin([1]).values\n",
    "is_adolescent_mask = included_subjects_covariates_df.Age_Sample_WBB.isin([2]).values\n",
    "is_adult_mask = included_subjects_covariates_df.Age_Sample_WBB.isin([3]).values\n",
    "is_pooled_mask = np.ones_like(is_adult_mask, dtype=bool) \n",
    "is_pediatric_or_adolescent_mask = is_pediatric_mask | is_adolescent_mask # We will use this for pediatric analyses\n",
    "\n",
    "# Create dict so we can access masks easily\n",
    "age_groups = ['pooled', 'adult', 'pediatric']\n",
    "age_group_masks_dict = dict(zip(age_groups, [is_pooled_mask, is_adult_mask, is_pediatric_or_adolescent_mask]))\n",
    "\n",
    "for age_group in age_groups:\n",
    "    print(\"N {} samples: {}\".format(age_group, sum(age_group_masks_dict[age_group])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aa3c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 214 1897\n"
     ]
    }
   ],
   "source": [
    "print(sum(is_pediatric_mask), sum(is_adolescent_mask), sum(is_adult_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c05419cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.134157657623291 5.390778320527733\n"
     ]
    }
   ],
   "source": [
    "print(fALFF_per_ROI.min(), fALFF_per_ROI.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dfdee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.3230038681054084 5.194765826580683\n"
     ]
    }
   ],
   "source": [
    "print(reHo_per_ROI.min(), reHo_per_ROI.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b27bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, in order to use fALFF and reHo features for classfication, we need to scale for better runtime:\n",
    "\n",
    "X_min, X_max = -5, 5\n",
    "\n",
    "fALFF_per_ROI_scaled = (fALFF_per_ROI - X_min) / (X_max - X_min)\n",
    "fALFF_per_network_scaled = (fALFF_per_network - X_min) / (X_max - X_min)\n",
    "reHo_per_ROI_scaled = (reHo_per_ROI - X_min) / (X_max - X_min)\n",
    "reHo_per_network_scaled = (reHo_per_network - X_min) / (X_max - X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7586c639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2148, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add demographic feature set using only Age and Sex as a \"baseline\" comparison\n",
    "\n",
    "demographic_data = np.c_[Age_vec, Sex_vec]\n",
    "demographic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "674c6b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI-to-ROI-FC features shape: (2148, 50403)\n",
      "network-FC features shape: (2148, 169)\n",
      "reHo-ROI features shape: (2148, 318)\n",
      "reHo-network features shape: (2148, 18)\n",
      "fALFF-ROI features shape: (2148, 318)\n",
      "fALFF-network features shape: (2148, 18)\n"
     ]
    }
   ],
   "source": [
    "# Create dict that maps feature labels with data\n",
    "\n",
    "feature_sets_dict = {\n",
    "#                      'demographical': demographic_data,\n",
    "                     'ROI-to-ROI-FC': pairwise_ROI_to_ROI_FC_vec,\n",
    "                     'network-FC': pairwise_network_FC_vec,\n",
    "                     'reHo-ROI': reHo_per_ROI_scaled,\n",
    "                     'reHo-network': reHo_per_network_scaled,\n",
    "                     'fALFF-ROI': fALFF_per_ROI_scaled,\n",
    "                     'fALFF-network': fALFF_per_network_scaled,\n",
    "                     }\n",
    "\n",
    "\n",
    "feature_labels = list(feature_sets_dict.keys())\n",
    "for feature_label in feature_labels:\n",
    "    print(\"{} features shape: {}\".format(feature_label, feature_sets_dict[feature_label].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7273df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI-to-ROI-FC features min: -1.7602020636513347, max: 2.5371584000790963\n",
      "network-FC features min: -0.6851071322346465, max: 1.4840383752234771\n",
      "reHo-ROI features min: 0.16769961318945917, max: 1.0194765826580683\n",
      "reHo-network features min: 0.31048786640167236, max: 0.7182867317721732\n",
      "fALFF-ROI features min: -0.013415765762329102, max: 1.0390778320527734\n",
      "fALFF-network features min: 0.25634422302246096, max: 0.8620645244242416\n"
     ]
    }
   ],
   "source": [
    "for feature_label in feature_labels:\n",
    "    print(\"{} features min: {}, max: {}\".format(feature_label, feature_sets_dict[feature_label].min(),\n",
    "                                                feature_sets_dict[feature_label].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60b534d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLF_RESULTS_DIR = os.path.join(pooled_data_dir, 'Results/Multivariate_Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2434d23",
   "metadata": {},
   "source": [
    "### ComBat experiments for Diagnosis, Sex, and site classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe2635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 96 subjects belonging to 5 different sites:\n",
      "\n",
      "Zurich_UCH\n",
      "Dresden\n",
      "Amsterdam_AMC\n",
      "Kyushu\n",
      "Barcelona_Bellvitge/COMPULSE_3T\n"
     ]
    }
   ],
   "source": [
    "class_label = 'Diagnosis'\n",
    "\n",
    "# For now only look into pairwise ROI-to-ROI FC\n",
    "X = pairwise_ROI_to_ROI_FC_vec.copy()\n",
    "\n",
    "# Only want to look into subjects that have Age and Sex covariates available. Not needed here\n",
    "has_cov_mask = [i not in IDs_missing_age_and_sex_covars for i in included_subject_ids]\n",
    "no_med_hc_mask = ~is_med_hc # We do NOT want to include any medicated HC \n",
    "subject_mask = merge_bool_masks(has_cov_mask, no_med_hc_mask)\n",
    "assert sum(~subject_mask) == 0\n",
    "\n",
    "# Filter out sites that have too little examples per class\n",
    "site_mask, counts_df = has_N_samples_per_class(included_subjects_covariates_df, class_label, subject_mask, \n",
    "                                               N_threshold=10, verbose=True)\n",
    "\n",
    "combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "\n",
    "y_Dx_masked = Dx_vec[combined_mask]\n",
    "y_Sex_masked = Sex_vec[combined_mask]\n",
    "y_Site_masked = LabelEncoder().fit_transform(groups_vec)[combined_mask]\n",
    "groups_masked = groups_vec[combined_mask]\n",
    "X_masked = X[combined_mask, :]\n",
    "\n",
    "# Create EO = matrix of effects of interest to keep, (age, sex, diagnosis)\n",
    "# EO = np.c_[demographic_data[combined_mask, :], y_Dx_masked]\n",
    "EO = demographic_data[combined_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69ea4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_clf_iter_with_combat_2023(X, y, EO, groups, clf_model, train_idx, test_idx):\n",
    "    combat = Combat()\n",
    "    scoring = Evaluater()\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
    "    EO_train, EO_test = EO[train_idx], EO[test_idx]\n",
    "\n",
    "    X_train = combat.fit_transform(Y=X_train, b=groups_train, X=EO_train, C=None)\n",
    "    X_test = combat.transform(Y=X_test, b=groups_test, X=EO_test, C=None)\n",
    "\n",
    "    clf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    y_score = clf_model.decision_function(X_test)\n",
    "\n",
    "    return scoring.evaluate_prediction(y_score=y_score,\n",
    "                                       y_pred=y_pred,\n",
    "                                       y_true=y_test)\n",
    "\n",
    "\n",
    "def run_multi_clf_iter_with_combat_2023(X, y, y_Dx, EO, groups, clf_model, train_idx, test_idx):\n",
    "    combat = Combat()\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
    "    EO_train, EO_test = EO[train_idx], EO[test_idx]\n",
    "\n",
    "    y_Dx_train, y_Dx_test = y_Dx[train_idx], y_Dx[test_idx]\n",
    "\n",
    "    X_train = combat.fit_transform(Y=X_train, b=groups_train, X=EO_train, C=None)\n",
    "    X_test = combat.transform(Y=X_test, b=groups_test, X=EO_test, C=None)\n",
    "\n",
    "    clf_model.fit(X_train, y_train)\n",
    "    y_pred = clf_model.predict(X_test)\n",
    "\n",
    "    # Calculate and save multiclass metrics\n",
    "    multiclass_report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    multiclass_metrics = np.concatenate((multiclass_report_df.loc[['accuracy'], 'precision'].values,\n",
    "                                         multiclass_report_df.loc['macro avg'].values,\n",
    "                                         multiclass_report_df.loc['weighted avg'].values))\n",
    "\n",
    "    return multiclass_report_df, multiclass_metrics\n",
    "\n",
    "\n",
    "def run_binary_clf_ComBat_experiment_2023(y_label, X, y, EO, groups, cv_splits, save_dir, n_jobs=20):\n",
    "    n_splits = len(cv_splits)\n",
    "\n",
    "    # Set up scoring evaluation\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "\n",
    "    # Dummy classifier that uses y_train to create priors for predictions\n",
    "    dummy_clf = DummyClassifier(strategy='stratified', random_state=0)\n",
    "\n",
    "    # Set up linear SVM with precomputed Kernel\n",
    "    K = pairwise_kernels(X, metric='linear')\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1, probability=False)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()),\n",
    "                         ('clf', svm)])\n",
    "\n",
    "    metric_scores_svm = np.zeros((n_splits, len(metric_labels)))\n",
    "    metric_scores_dummy = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        K_train, K_test = K[np.ix_(train_idx, train_idx)], K[np.ix_(test_idx, train_idx)]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        svm_pipe.fit(K_train, y_train)\n",
    "        dummy_clf.fit(K_train, y_train)\n",
    "\n",
    "        y_score_svm = svm_pipe.decision_function(K_test)\n",
    "        y_pred_svm = svm_pipe.predict(K_test)\n",
    "\n",
    "        y_pred_dummy = dummy_clf.predict(K_test)\n",
    "\n",
    "        # Calculate and save metrics\n",
    "        metric_scores_svm[i_split] = scoring.evaluate_prediction(y_score=y_score_svm, y_pred=y_pred_svm,\n",
    "                                                                 y_true=y_test)\n",
    "\n",
    "        metric_scores_dummy[i_split] = scoring.evaluate_prediction(y_score=y_pred_dummy, y_pred=y_pred_dummy,\n",
    "                                                                   y_true=y_test)\n",
    "\n",
    "    print(\"Dummy classifier performance:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores_dummy[:, m_idx].mean()))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"SVM performance without ComBat:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores_svm[:, m_idx].mean()))\n",
    "    print(\"\")\n",
    "\n",
    "    # Now run ComBat!\n",
    "    svm_combat = SVC(kernel='linear', class_weight='balanced', C=1, probability=False)\n",
    "    svm_pipe_combat = Pipeline([('centerer', StandardScaler(with_std=False)),\n",
    "                                ('clf', svm_combat)])\n",
    "\n",
    "    metric_scores_svm_combat = Parallel(n_jobs=n_jobs, verbose=1)(delayed(run_binary_clf_iter_with_combat_2023)\n",
    "                                                                  (X, y, EO, groups, svm_pipe_combat, train_idx, test_idx)\n",
    "                                                                  for i_split, (train_idx, test_idx)\n",
    "                                                                  in enumerate(cv_splits))\n",
    "    metric_scores_svm_combat = np.array(metric_scores_svm_combat, dtype=object)\n",
    "\n",
    "    print(\"SVM performance with ComBat:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores_svm_combat[:, m_idx].mean()))\n",
    "    print(\"\")\n",
    "\n",
    "    # Save results\n",
    "    save_path = os.path.join(save_dir, 'results_' + y_label + '_clf.npz')\n",
    "\n",
    "    np.savez(save_path,\n",
    "             y_label=y_label,\n",
    "             X=X, y=y, groups=groups,\n",
    "             metric_scores_dummy=metric_scores_dummy,\n",
    "             metric_scores_svm=metric_scores_svm,\n",
    "             metric_scores_svm_combat=metric_scores_svm_combat,\n",
    "             cv_splits=cv_splits,\n",
    "             )\n",
    "\n",
    "    return metric_scores_dummy, metric_scores_svm, metric_scores_svm_combat, metric_labels\n",
    "\n",
    "\n",
    "def run_multi_clf_ComBat_experiment_2023(y_label, X, y, y_Dx, EO, groups, cv_splits, save_dir, n_jobs=20):\n",
    "    n_splits = len(cv_splits)\n",
    "\n",
    "    # Dummy classifier that uses y_train to create priors for predictions\n",
    "    dummy_clf = DummyClassifier(strategy='stratified', random_state=0)\n",
    "\n",
    "    # Set up SVM\n",
    "    K = pairwise_kernels(X, metric='linear')\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1, probability=False, decision_function_shape='ovr')\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()),\n",
    "                         ('clf', svm)])\n",
    "\n",
    "    multiclass_metric_labels = ['accuracy', 'macro_avg_precision', 'macro_avg_recall', 'macro_avg_f1_score',\n",
    "                                'macro_avg_support', 'weigh_avg_precision', 'weigh_avg_recall', 'weigh_avg_f1_score',\n",
    "                                'weigh_avg_support']\n",
    "\n",
    "    multiclass_metrics_svm = np.zeros((n_splits, len(multiclass_metric_labels)))\n",
    "    multiclass_metrics_dummy = np.zeros((n_splits, len(multiclass_metric_labels)))\n",
    "\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        K_train, K_test = K[np.ix_(train_idx, train_idx)], K[np.ix_(test_idx, train_idx)]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        svm_pipe.fit(K_train, y_train)\n",
    "        dummy_clf.fit(K_train, y_train)\n",
    "\n",
    "        y_pred_svm = svm_pipe.predict(K_test)\n",
    "        y_pred_dummy = dummy_clf.predict(K_test)\n",
    "\n",
    "        # Calculate and save multiclass metrics\n",
    "        report_svm = pd.DataFrame(classification_report(y_test, y_pred_svm, output_dict=True)).transpose()\n",
    "        report_dummy = pd.DataFrame(classification_report(y_test, y_pred_dummy, output_dict=True)).transpose()\n",
    "\n",
    "        multiclass_metrics_svm_ = np.concatenate((report_svm.loc[['accuracy'], 'precision'].values,\n",
    "                                                  report_svm.loc['macro avg'].values,\n",
    "                                                  report_svm.loc['weighted avg'].values))\n",
    "        multiclass_metrics_dummy_ = np.concatenate((report_dummy.loc[['accuracy'], 'precision'].values,\n",
    "                                                    report_dummy.loc['macro avg'].values,\n",
    "                                                    report_dummy.loc['weighted avg'].values))\n",
    "\n",
    "        multiclass_metrics_svm[i_split, :] = multiclass_metrics_svm_\n",
    "        multiclass_metrics_dummy[i_split, :] = multiclass_metrics_dummy_\n",
    "\n",
    "    print(\"Dummy classifier performance:\")\n",
    "    for m_idx, m_label in enumerate(multiclass_metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label.capitalize(), multiclass_metrics_dummy[:, m_idx].mean()))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"SVM performance without ComBat:\")\n",
    "    for m_idx, m_label in enumerate(multiclass_metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label.capitalize(), multiclass_metrics_svm[:, m_idx].mean()))\n",
    "    print(\"\")\n",
    "\n",
    "    svm_combat = SVC(kernel='linear', class_weight='balanced', C=1, probability=False)\n",
    "    svm_pipe_combat = Pipeline([('centerer', StandardScaler(with_std=False)),\n",
    "                                ('clf', svm_combat)])\n",
    "\n",
    "    multiclass_report_df_svm_combat, multiclass_metrics_svm_combat = zip(*Parallel(n_jobs=n_jobs, verbose=1)\n",
    "    (delayed(run_multi_clf_iter_with_combat_2023)(X, y, y_Dx, EO,\n",
    "                                             groups,\n",
    "                                             svm_pipe_combat,\n",
    "                                             train_idx,\n",
    "                                             test_idx)\n",
    "     for i_split, (train_idx, test_idx) in enumerate(cv_splits)))\n",
    "\n",
    "    multiclass_metrics_svm_combat = np.array(multiclass_metrics_svm_combat, dtype=object)\n",
    "\n",
    "    print(\"SVM performance with ComBat:\")\n",
    "    for m_idx, m_label in enumerate(multiclass_metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label.capitalize(), multiclass_metrics_svm_combat[:, m_idx].mean()))\n",
    "    print(\"\")\n",
    "\n",
    "    # Save results\n",
    "    save_path = os.path.join(save_dir, 'results_' + y_label + '_clf.npz')\n",
    "\n",
    "    np.savez(save_path,\n",
    "             y_label=y_label,\n",
    "             X=X, y=y, groups=groups,\n",
    "             multiclass_metrics_dummy=multiclass_metrics_dummy,\n",
    "             multiclass_metrics_svm=multiclass_metrics_svm,\n",
    "             multiclass_metrics_svm_combat=multiclass_metrics_svm_combat,\n",
    "             cv_splits=cv_splits,\n",
    "             )\n",
    "\n",
    "    return multiclass_metrics_dummy, multiclass_metrics_svm, multiclass_metrics_svm_combat, multiclass_metric_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f2323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 96 subjects belonging to 5 different sites:\n",
      "\n",
      "Zurich_UCH\n",
      "Dresden\n",
      "Amsterdam_AMC\n",
      "Kyushu\n",
      "Barcelona_Bellvitge/COMPULSE_3T\n",
      "Dummy classifier performance:\n",
      "mean accuracy: 0.49\n",
      "mean balanced_accuracy: 0.49\n",
      "mean AUC: 0.49\n",
      "mean F1: 0.49\n",
      "mean recall: 0.49\n",
      "mean precision: 0.49\n",
      "mean sensitivity: 0.49\n",
      "mean specificity: 0.49\n",
      "mean positive_predictive_value: 0.49\n",
      "mean negative_predictive_value: 0.49\n",
      "\n",
      "SVM performance without ComBat:\n",
      "mean accuracy: 0.61\n",
      "mean balanced_accuracy: 0.61\n",
      "mean AUC: 0.66\n",
      "mean F1: 0.61\n",
      "mean recall: 0.62\n",
      "mean precision: 0.61\n",
      "mean sensitivity: 0.62\n",
      "mean specificity: 0.60\n",
      "mean positive_predictive_value: 0.61\n",
      "mean negative_predictive_value: 0.61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 20.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM performance with ComBat:\n",
      "mean accuracy: 0.59\n",
      "mean balanced_accuracy: 0.59\n",
      "mean AUC: 0.63\n",
      "mean F1: 0.59\n",
      "mean recall: 0.60\n",
      "mean precision: 0.59\n",
      "mean sensitivity: 0.60\n",
      "mean specificity: 0.59\n",
      "mean positive_predictive_value: 0.59\n",
      "mean negative_predictive_value: 0.59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier performance:\n",
      "mean accuracy: 0.50\n",
      "mean balanced_accuracy: 0.50\n",
      "mean AUC: 0.50\n",
      "mean F1: 0.50\n",
      "mean recall: 0.50\n",
      "mean precision: 0.50\n",
      "mean sensitivity: 0.50\n",
      "mean specificity: 0.50\n",
      "mean positive_predictive_value: 0.50\n",
      "mean negative_predictive_value: 0.50\n",
      "\n",
      "SVM performance without ComBat:\n",
      "mean accuracy: 0.75\n",
      "mean balanced_accuracy: 0.75\n",
      "mean AUC: 0.83\n",
      "mean F1: 0.74\n",
      "mean recall: 0.73\n",
      "mean precision: 0.76\n",
      "mean sensitivity: 0.73\n",
      "mean specificity: 0.78\n",
      "mean positive_predictive_value: 0.76\n",
      "mean negative_predictive_value: 0.74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM performance with ComBat:\n",
      "mean accuracy: 0.73\n",
      "mean balanced_accuracy: 0.73\n",
      "mean AUC: 0.80\n",
      "mean F1: 0.73\n",
      "mean recall: 0.71\n",
      "mean precision: 0.74\n",
      "mean sensitivity: 0.71\n",
      "mean specificity: 0.75\n",
      "mean positive_predictive_value: 0.74\n",
      "mean negative_predictive_value: 0.73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier performance:\n",
      "mean Accuracy: 0.06\n",
      "mean Macro_avg_precision: 0.03\n",
      "mean Macro_avg_recall: 0.03\n",
      "mean Macro_avg_f1_score: 0.03\n",
      "mean Macro_avg_support: 410.40\n",
      "mean Weigh_avg_precision: 0.07\n",
      "mean Weigh_avg_recall: 0.06\n",
      "mean Weigh_avg_f1_score: 0.07\n",
      "mean Weigh_avg_support: 410.40\n",
      "\n",
      "SVM performance without ComBat:\n",
      "mean Accuracy: 0.73\n",
      "mean Macro_avg_precision: 0.73\n",
      "mean Macro_avg_recall: 0.64\n",
      "mean Macro_avg_f1_score: 0.66\n",
      "mean Macro_avg_support: 410.40\n",
      "mean Weigh_avg_precision: 0.74\n",
      "mean Weigh_avg_recall: 0.73\n",
      "mean Weigh_avg_f1_score: 0.71\n",
      "mean Weigh_avg_support: 410.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  7.7min\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 38.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM performance with ComBat:\n",
      "mean Accuracy: 0.03\n",
      "mean Macro_avg_precision: 0.03\n",
      "mean Macro_avg_recall: 0.02\n",
      "mean Macro_avg_f1_score: 0.02\n",
      "mean Macro_avg_support: 410.40\n",
      "mean Weigh_avg_precision: 0.07\n",
      "mean Weigh_avg_recall: 0.03\n",
      "mean Weigh_avg_f1_score: 0.04\n",
      "mean Weigh_avg_support: 410.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    }
   ],
   "source": [
    "# For these ComBat experiments we want to ensure same subjects are used for Dx, Sex and Site classification\n",
    "\n",
    "outer_cv_folds, outer_cv_repeats = 5, 20\n",
    "inner_cv_folds, inner_cv_repeats = 5, 1\n",
    "\n",
    "class_label = 'Diagnosis'\n",
    "\n",
    "combat_save_dir = os.path.join(CLF_RESULTS_DIR, 'ComBat_experiments_2023_EO_AgeSex')\n",
    "ensure_folder(combat_save_dir)\n",
    "\n",
    "# For now only look into pairwise ROI-to-ROI FC\n",
    "X = pairwise_ROI_to_ROI_FC_vec.copy()\n",
    "\n",
    "# Only want to look into subjects that have Age and Sex covariates available. Not needed here\n",
    "has_cov_mask = [i not in IDs_missing_age_and_sex_covars for i in included_subject_ids]\n",
    "no_med_hc_mask = ~is_med_hc # We do NOT want to include any medicated HC \n",
    "subject_mask = merge_bool_masks(has_cov_mask, no_med_hc_mask)\n",
    "assert sum(~subject_mask) == 0\n",
    "\n",
    "# Filter out sites that have too little examples per class\n",
    "site_mask, counts_df = has_N_samples_per_class(included_subjects_covariates_df, class_label, subject_mask, \n",
    "                                               N_threshold=10, verbose=True)\n",
    "\n",
    "combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "\n",
    "y_Dx_masked = Dx_vec[combined_mask]\n",
    "y_Sex_masked = Sex_vec[combined_mask]\n",
    "y_Site_masked = LabelEncoder().fit_transform(groups_vec)[combined_mask]\n",
    "groups_masked = groups_vec[combined_mask]\n",
    "X_masked = X[combined_mask, :]\n",
    "\n",
    "# Make sure no NaNs are present in any of the labels to predict\n",
    "for v in [y_Dx_masked, y_Sex_masked, y_Site_masked]:\n",
    "    assert np.sum(np.isnan(v)) == 0\n",
    "\n",
    "    \n",
    "# Ensure we use same CV splits across different classification tasks: stratified for Site x Diagnosis \n",
    "cv_splits = repeated_group_stratified_KFold_splits(y_Dx_masked, groups_masked, \n",
    "                                                   n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                   seed=0, verbose=True)\n",
    "n_splits=len(cv_splits)\n",
    "\n",
    "    \n",
    "# Experiment 1: What is Dx clf performance for Dummy classifier, SVM without ComBat, and with ComBat?\n",
    "y_label = 'Diagnosis'\n",
    "metric_scores_dummy, metric_scores_svm, metric_scores_svm_combat, metric_labels = run_binary_clf_ComBat_experiment_2023(\n",
    "                                                                                                    y_label,\n",
    "                                                                                                    X_masked, \n",
    "                                                                                                    y_Dx_masked,\n",
    "                                                                                                    EO,\n",
    "                                                                                                    groups_masked, \n",
    "                                                                                                    cv_splits,\n",
    "                                                                                                    combat_save_dir)\n",
    "# Plot classification results\n",
    "plot_ComBat_experiment_results(y_label, metric_scores_dummy, metric_scores_svm, metric_scores_svm_combat,\n",
    "                               metric_labels, combat_save_dir)\n",
    "\n",
    "\n",
    "# Experiment 2: What is Dx clf performance for Dummy classifier, SVM without ComBat, and with ComBat?\n",
    "y_label = 'Sex'\n",
    "metric_scores_dummy, metric_scores_svm, metric_scores_svm_combat, metric_labels = run_binary_clf_ComBat_experiment_2023(\n",
    "                                                                                                    y_label,\n",
    "                                                                                                    X_masked, \n",
    "                                                                                                    y_Sex_masked,\n",
    "                                                                                                    EO,\n",
    "                                                                                                    groups_masked, \n",
    "                                                                                                    cv_splits,\n",
    "                                                                                                    combat_save_dir)\n",
    "# Plot classification results\n",
    "plot_ComBat_experiment_results(y_label, metric_scores_dummy, metric_scores_svm, metric_scores_svm_combat,\n",
    "                               metric_labels, combat_save_dir)\n",
    "\n",
    "\n",
    "# Experiment 3: What is Site (multi-)clf performance for Dummy classifier, SVM without ComBat, and with ComBat?\n",
    "y_label = 'Site'\n",
    "(multiclass_metrics_dummy, multiclass_metrics_svm, \n",
    "multiclass_metrics_svm_combat, multiclass_metric_labels) = run_multi_clf_ComBat_experiment_2023(y_label,\n",
    "                                                                                                X_masked, \n",
    "                                                                                                y_Site_masked,\n",
    "                                                                                                y_Dx_masked,\n",
    "                                                                                                EO,\n",
    "                                                                                                groups_masked, \n",
    "                                                                                                cv_splits,\n",
    "                                                                                                combat_save_dir)\n",
    "# Multi site chance level performance is 1/N sites\n",
    "multisite_y_chance = float(1) / len(np.unique(y_Site_masked))\n",
    "\n",
    "# Plot classification results\n",
    "plot_ComBat_experiment_results(y_label, multiclass_metrics_dummy, multiclass_metrics_svm, \n",
    "                               multiclass_metrics_svm_combat, multiclass_metric_labels, combat_save_dir,\n",
    "                               y_chance=multisite_y_chance, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40523b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2918d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearch(X, y, pipeline, grid_params, cv_splits, n_jobs, scoring='roc_auc', verbose=False):\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, param_grid=grid_params, cv=cv_splits, verbose=verbose, scoring=scoring, \n",
    "                        n_jobs=n_jobs, pre_dispatch='2*n_jobs', refit=True)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    best_params = [grid.best_params_[param] for param in sorted(grid.best_params_)]\n",
    "    \n",
    "    return grid.best_estimator_, best_params, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdd447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise gridsearch params which are identical for all classifications\n",
    "\n",
    "C_range = np.logspace(-3, 1, 5) # [0.001, 0.01, 0.1, 1.0, 10]\n",
    "grid_params_lin_K = {'clf__C' : C_range} \n",
    "\n",
    "# gamma_range = np.logspace(-4, 0, 5) # [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# grid_params_rbf_K = {'clf__C' : C_range,\n",
    "#                      'clf__gamma' : gamma_range} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6f1708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use site and class stratified 5 Fold CV with 20 repeats\n",
    "\n",
    "outer_cv_folds, outer_cv_repeats = 5, 20\n",
    "inner_cv_folds, inner_cv_repeats = 5, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b8477",
   "metadata": {},
   "source": [
    "### Classification seperately for pediatric (<18 years) and adult (>= 18 years) samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89c6f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis_CLF_pooled_SAMPLES_demographical_FEATURES\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2893\n",
      "Excluded 96 subjects belonging to 5 different sites:\n",
      "\n",
      "Zurich_UCH\n",
      "Dresden\n",
      "Amsterdam_AMC\n",
      "Kyushu\n",
      "Barcelona_Bellvitge/COMPULSE_3T\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 1/100 in 0.80 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 2/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 3/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 4/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 5/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 6/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 7/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 8/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 9/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 10/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 11/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 12/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 13/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 14/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 15/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 16/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 17/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 18/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 19/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 20/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 21/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 22/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 23/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 24/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 25/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 26/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 27/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 28/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 29/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 30/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 31/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 32/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 33/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 34/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 35/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 36/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 37/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 38/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 39/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 40/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 41/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 42/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 43/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 44/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 45/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 46/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 47/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 48/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 49/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 50/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 51/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 52/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 53/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 54/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 55/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 56/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 57/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 58/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 59/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 60/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 61/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 62/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 63/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 64/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 65/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 66/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 67/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 68/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 69/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 70/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 71/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 72/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 73/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 74/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 75/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 76/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 77/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 78/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 79/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 80/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 81/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 82/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 83/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 84/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 85/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 86/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 87/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 88/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 89/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 90/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 91/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 92/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 93/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 94/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 95/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 96/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 97/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 98/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 99/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 100/100 in 0.01 minutes: \n",
      "\n",
      "Finished classification in 1.42 minutes\n",
      "\n",
      "Performance averaged across splits:\n",
      "mean accuracy: 0.53\n",
      "mean balanced_accuracy: 0.53\n",
      "mean AUC: 0.55\n",
      "mean F1: 0.52\n",
      "mean recall: 0.52\n",
      "mean precision: 0.53\n",
      "mean sensitivity: 0.52\n",
      "mean specificity: 0.53\n",
      "mean positive_predictive_value: 0.53\n",
      "mean negative_predictive_value: 0.53\n",
      "\n",
      "Diagnosis_CLF_adult_SAMPLES_demographical_FEATURES\n",
      "Excluded 80 subjects belonging to 8 different sites:\n",
      "\n",
      "Zurich_UCH\n",
      "Dresden\n",
      "Vancouver_BCCHR\n",
      "Amsterdam_AMC\n",
      "NYSPI_Columbia/Pediatric\n",
      "Barcelona_HCPB\n",
      "Barcelona_Bellvitge/COMPULSE_3T\n",
      "Kyushu\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 1/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 2/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 3/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 4/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 5/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 6/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 7/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 8/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 9/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 10/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 11/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 12/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 13/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 14/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 15/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 16/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 17/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 18/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 19/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 20/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 21/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 22/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 23/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 24/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 25/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 26/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 27/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 28/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 29/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 30/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 31/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 32/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 33/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 34/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 35/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 36/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 37/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 38/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 39/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 40/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 41/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 42/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 43/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 44/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 45/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 46/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 47/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 48/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 49/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 50/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 51/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 52/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 53/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 54/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 55/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 56/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 57/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 58/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 59/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 60/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 61/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 62/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 63/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 64/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 65/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 66/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 67/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 68/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 69/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 70/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 71/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 72/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 73/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 74/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 75/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 76/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 77/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 78/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 79/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 80/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 81/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 82/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 83/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 84/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 85/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 86/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 87/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 88/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 89/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 90/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 91/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 92/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 93/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 94/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 95/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 96/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 97/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 98/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 99/100 in 0.01 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 100/100 in 0.01 minutes: \n",
      "\n",
      "Finished classification in 0.55 minutes\n",
      "\n",
      "Performance averaged across splits:\n",
      "mean accuracy: 0.53\n",
      "mean balanced_accuracy: 0.53\n",
      "mean AUC: 0.56\n",
      "mean F1: 0.53\n",
      "mean recall: 0.53\n",
      "mean precision: 0.53\n",
      "mean sensitivity: 0.53\n",
      "mean specificity: 0.54\n",
      "mean positive_predictive_value: 0.53\n",
      "mean negative_predictive_value: 0.54\n",
      "\n",
      "Diagnosis_CLF_pediatric_SAMPLES_demographical_FEATURES\n",
      "Excluded 47 subjects belonging to 8 different sites:\n",
      "\n",
      "Zurich_UCH\n",
      "Brazil\n",
      "Bangalore_NIMHANS\n",
      "Dresden\n",
      "Shanghai_SMCH\n",
      "Braga_UMinho/Braga_3T\n",
      "Kyushu\n",
      "Seoul_SNU\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 1/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 2/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 3/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 4/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 5/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 6/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 7/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 8/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 9/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 10/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 11/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 12/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 13/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 14/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 15/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 16/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 17/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 18/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 19/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 20/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 21/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 22/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 23/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 24/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 25/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 26/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 27/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 28/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 29/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 30/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 31/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 32/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 33/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 34/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 35/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 36/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 37/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 38/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 39/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 40/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 41/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 42/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 43/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 44/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 45/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 46/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 47/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 48/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 49/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 50/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 51/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 52/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 53/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 54/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 55/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 56/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 57/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 58/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 59/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 60/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 61/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 62/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 63/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 64/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 65/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 66/100 in 0.00 minutes: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 67/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 68/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 69/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 70/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 71/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 72/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 73/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 74/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 75/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 76/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 77/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 78/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 79/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 80/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 81/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 82/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 83/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 84/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 85/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 86/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 87/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 88/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 89/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 90/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished CV iteration 91/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 92/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 93/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 94/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 95/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 96/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 97/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 98/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 99/100 in 0.00 minutes: \n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Finished CV iteration 100/100 in 0.00 minutes: \n",
      "\n",
      "Finished classification in 0.06 minutes\n",
      "\n",
      "Performance averaged across splits:\n",
      "mean accuracy: 0.47\n",
      "mean balanced_accuracy: 0.47\n",
      "mean AUC: 0.43\n",
      "mean F1: 0.13\n",
      "mean recall: 0.13\n",
      "mean precision: 0.13\n",
      "mean sensitivity: 0.13\n",
      "mean specificity: 0.82\n",
      "mean positive_predictive_value: 0.13\n",
      "mean negative_predictive_value: 0.46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/wbbruin/Desktop/ENIGMA_OCD_RSFMRI_2021/notebooks/scripts/evaluation_classifier.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ppv_score = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1, dtype=np.float)\n",
      "/data/wbbruin/anaconda2/envs/ENIGMA_OCD_RSFMRI/lib/python3.9/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '1_Main_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES'\n",
    "class_label = 'Diagnosis'\n",
    "y = Dx_vec.copy()\n",
    "\n",
    "# All analysis-specific subject masking can be defined BEFORE looping through age groups and feature sets:\n",
    "has_y_mask = ~np.isnan(y) # Redundant here, but we'll need it for Med/Sev/AO classifications\n",
    "\n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label in product(age_groups, feature_labels): \n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    subject_mask = merge_bool_masks(has_y_mask, age_group_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea00a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a) Medicated / Unmedicated OCD vs Controls\n",
    "\n",
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '2a_Medication_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES_{}_FILTER'\n",
    "class_label = 'Diagnosis'\n",
    "y = Dx_vec.copy()\n",
    "\n",
    "# All analysis-specific subject masking can be defined BEFORE looping through age groups and feature sets:\n",
    "\n",
    "# Only want to look into subjects that have Age and Sex covariates available\n",
    "has_y_mask = ~np.isnan(y) # Redundant here, but we'll need it for Med/Sev/AO classifacations\n",
    "\n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label, filter_label in product(age_groups, feature_labels, Dx_med_filter_labels):\n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label, filter_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    filter_mask = Dx_med_filter_dict[filter_label]\n",
    "    subject_mask = merge_bool_masks(has_y_mask, age_group_mask, filter_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2815ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b) Early / Late Onset OCD vs Controls\n",
    "\n",
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '2b_Age_of_Onset_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES_{}_FILTER'\n",
    "class_label = 'Diagnosis'\n",
    "y = Dx_vec.copy()\n",
    "\n",
    "# All analysis-specific subject masking can be defined BEFORE looping through age groups and feature sets:\n",
    "has_y_mask = ~np.isnan(y) # Redundant here, but we'll need it for Med/Sev/AO classifacations\n",
    "\n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label, filter_label in product(age_groups, feature_labels, Dx_AO_filter_labels):\n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label, filter_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    filter_mask = Dx_AO_filter_dict[filter_label]\n",
    "    subject_mask = merge_bool_masks(has_y_mask, age_group_mask, filter_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c) Low / High Severity OCD vs Controls\n",
    "\n",
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '2c_Severity_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES_{}_FILTER'\n",
    "class_label = 'Diagnosis'\n",
    "y = Dx_vec.copy()\n",
    "\n",
    "# All analysis-specific subject masking can be defined BEFORE looping through age groups and feature sets:\n",
    "has_y_mask = ~np.isnan(y) # Redundant here, but we'll need it for Med/Sev/AO classifacations\n",
    "\n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label, filter_label in product(age_groups, feature_labels, Dx_sev_filter_labels):\n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label, filter_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    filter_mask = Dx_sev_filter_dict[filter_label]\n",
    "    subject_mask = merge_bool_masks(has_y_mask, age_group_mask, filter_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e4d95",
   "metadata": {},
   "source": [
    "### 3) Classifications within subgroups of OCD patients ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af72963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Investigate effects of medication, AO and severity in patients only\n",
    "\n",
    "is_med_pt_or_unmed_pt_mask = is_med_pt | is_unmed_pt \n",
    "is_early_AO_pt_or_late_AO_pt_mask = is_early_AO_pt | is_late_AO_pt\n",
    "is_low_sev_pt_or_high_sev_pt_mask = is_low_sev_pt | is_high_sev_pt \n",
    "\n",
    "# \"Medication status at time of scan (1=naive, 2=unmedicated, 3=medicated) recoded to Unmed = 0, Med = 1\n",
    "assert included_subjects_covariates_df.loc[is_med_pt_or_unmed_pt_mask].Diagnosis.unique()[0] ==  1\n",
    "med_vec = np.array(included_subjects_covariates_df.Medication_status)\n",
    "med_vec = np.where(med_vec==1, 0, med_vec)\n",
    "med_vec = np.where(med_vec==2, 0, med_vec)\n",
    "med_vec = np.where(med_vec==3, 1, med_vec)\n",
    "assert len(np.unique(med_vec[is_med_pt_or_unmed_pt_mask])) == 2\n",
    "\n",
    "# Early-onset/Child OCD patients (onset before age 18) and Late-onset/adult OCD patients (onset at age 18 or older)\n",
    "# Recode from 1=child, 2=adult to, 0 and 1 respectively\n",
    "assert included_subjects_covariates_df.loc[is_early_AO_pt_or_late_AO_pt_mask].Diagnosis.unique()[0] ==  1\n",
    "AO_vec = np.array(included_subjects_covariates_df.Age_of_onset)\n",
    "AO_vec = np.where(AO_vec==1, 0, AO_vec)\n",
    "AO_vec = np.where(AO_vec==2, 1, AO_vec)\n",
    "assert len(np.unique(AO_vec[is_early_AO_pt_or_late_AO_pt_mask])) == 2\n",
    "\n",
    "# (YBOCS <= 25; mild-moderate) and high severity (YBOCS > 25; moderate-severe) OCD; recode to Low=0, High=1\n",
    "assert included_subjects_covariates_df.loc[is_low_sev_pt_or_high_sev_pt_mask].Diagnosis.unique()[0] ==  1\n",
    "sev_vec = np.array(included_subjects_covariates_df['Y-BOCS'])\n",
    "sev_vec[sev_vec <= median_sev] = 0\n",
    "sev_vec[sev_vec > median_sev] = 1\n",
    "assert len(np.unique(sev_vec[is_low_sev_pt_or_high_sev_pt_mask])) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a944f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a) Medicated (coded=1) vs Unmedicated OCD (coded=0)\n",
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '3a_Medication_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES'\n",
    "\n",
    "# Only have to change these 3 variables for different subgroup analyses.\n",
    "filter_mask = is_med_pt_or_unmed_pt_mask # Specific for analyses: only look into patients subgroups    \n",
    "class_label = 'Medication'\n",
    "y = med_vec.copy()\n",
    "                           \n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label in product(age_groups, feature_labels):\n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    subject_mask = merge_bool_masks(age_group_mask, filter_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b) Child/Early onset (coded=0) vs Late/Adult onset OCD (coded=1)\n",
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '3b_Age_of_Onset_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES'\n",
    "\n",
    "# Only have to change these 3 variables for different subgroup analyses.\n",
    "filter_mask = is_early_AO_pt_or_late_AO_pt_mask # Specific for analyses: only look into patients subgroups    \n",
    "class_label = 'Age_of_Onset'\n",
    "y = AO_vec.copy()\n",
    "                           \n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label in product(age_groups, feature_labels):\n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    subject_mask = merge_bool_masks(age_group_mask, filter_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edebca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3c) High Severity (coded=1) vs Low Severity OCD (coded=0)\n",
    "RESULTS_DIR = os.path.join(CLF_RESULTS_DIR, '3c_Severity_Analyses')\n",
    "\n",
    "N_jobs = 20 \n",
    "\n",
    "title_template = '{}_CLF_{}_SAMPLES_{}_FEATURES'\n",
    "\n",
    "# Only have to change these 3 variables for different subgroup analyses.\n",
    "filter_mask = is_low_sev_pt_or_high_sev_pt_mask # Specific for analyses: only look into patients subgroups.      \n",
    "class_label = 'Severity'\n",
    "y = sev_vec.copy()\n",
    "                           \n",
    "# Now iterate over all age groups and feature sets\n",
    "for age_group, feature_label in product(age_groups, feature_labels):\n",
    "    \n",
    "    title = title_template.format(class_label, age_group, feature_label)\n",
    "    print(title)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_DIR, title)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Output directory already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    ensure_folder(save_dir)\n",
    "    \n",
    "    X = feature_sets_dict[feature_label]\n",
    "    \n",
    "    # Merge subject masks\n",
    "    age_group_mask = age_group_masks_dict[age_group]\n",
    "    subject_mask = merge_bool_masks(age_group_mask, filter_mask)\n",
    "    \n",
    "    # Create copy of covariates df and append class_label vec is this is not included already\n",
    "    tmp_covariates_df = included_subjects_covariates_df.copy()\n",
    "    if class_label not in tmp_covariates_df.columns:\n",
    "        tmp_covariates_df[class_label] = y\n",
    "        \n",
    "    # Filter out sites that have too little examples per class\n",
    "    site_mask, counts_df = has_N_samples_per_class(tmp_covariates_df, class_label, subject_mask, \n",
    "                                                   N_threshold=10, verbose=True)\n",
    "    \n",
    "    # Save overview of included sites and class counts\n",
    "    counts_df.to_csv(os.path.join(save_dir, 'class_counts.csv'), index=False)\n",
    "    \n",
    "    if counts_df.shape[0] < 2:\n",
    "        print(\"Not enough samples to run analysis. Skipping!\")\n",
    "        continue\n",
    "    \n",
    "    # Combine analysis-specific subject mask with site mask\n",
    "    combined_mask = merge_bool_masks(subject_mask, site_mask)\n",
    "    \n",
    "    # Apply combined mask\n",
    "    y_, groups_ = y[combined_mask], groups_vec[combined_mask]\n",
    "    X_ = X[combined_mask, :]\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv_splits = repeated_group_stratified_KFold_splits(y_, groups_, \n",
    "                                                       n_folds=outer_cv_folds, n_repeats=outer_cv_repeats, \n",
    "                                                       seed=0, verbose=True)\n",
    "    n_splits=len(cv_splits)\n",
    "\n",
    "    # Initialize scoring evaluaters and classification pipeline\n",
    "    scoring = Evaluater()\n",
    "    metric_labels = scoring.evaluate_labels()\n",
    "    metric_scores = np.zeros((n_splits, len(metric_labels)))\n",
    "\n",
    "    best_params_lin = np.zeros((n_splits))\n",
    "    \n",
    "    y_predictions = np.ones((n_splits, len(y_))) * -1\n",
    "    y_scores = np.ones((n_splits, len(y_))) * -1\n",
    "\n",
    "    svm = SVC(kernel='precomputed', class_weight='balanced', C=1)\n",
    "    svm_pipe = Pipeline([('centerer', KernelCenterer()), \n",
    "                         ('clf', svm)])\n",
    "\n",
    "    # Precompute Kernels\n",
    "    K_lin = pairwise_kernels(X_, metric='linear')\n",
    "    \n",
    "    t1 = time()    \n",
    "    \n",
    "    # Run cross-validation\n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        K_lin_train, K_lin_test = K_lin[np.ix_(train_idx, train_idx)], K_lin[np.ix_(test_idx, train_idx)]   \n",
    "        y_train, y_test = y_[train_idx], y_[test_idx]\n",
    "        groups_train = groups_[train_idx]\n",
    "\n",
    "        nested_cv_splits = repeated_group_stratified_KFold_splits(y_train, groups_train, \n",
    "                                                                  n_folds=inner_cv_folds, n_repeats=inner_cv_repeats,\n",
    "                                                                  seed=0, verbose=True)\n",
    "\n",
    "        # Run gridsearch for linear Kernel (C)\n",
    "        lin_model, lin_best_params, lin_best_score = run_gridsearch(K_lin_train, y_train, \n",
    "                                                                    svm_pipe, grid_params_lin_K, \n",
    "                                                                    nested_cv_splits, n_jobs=20, \n",
    "                                                                    scoring='balanced_accuracy', verbose=True)\n",
    "        y_score = lin_model.decision_function(K_lin_test) \n",
    "        y_pred = lin_model.predict(K_lin_test)\n",
    "        metric_scores[i_split, :] = scoring.evaluate_prediction(y_score=y_score, y_pred=y_pred, y_true=y_test)\n",
    "        best_params_lin[i_split] = lin_best_params[0]\n",
    "        y_predictions[i_split, test_idx] = y_pred\n",
    "        y_scores[i_split, test_idx] = y_score\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        print(\"Finished CV iteration {}/{} in {:.2f} minutes: \".format(i_split+1, n_splits, (t4-t3)/60.))\n",
    "\n",
    "    t2 = time() \n",
    "    \n",
    "    print()\n",
    "    print(\"Finished classification in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance averaged across splits:\")\n",
    "    for m_idx, m_label in enumerate(metric_labels):\n",
    "        print(\"mean {}: {:.2f}\".format(m_label, metric_scores[:, m_idx].mean()))\n",
    "    print()\n",
    "        \n",
    "    # Save classification results\n",
    "    np.savez(os.path.join(save_dir, 'clf_results.npz'), \n",
    "             cv_splits=cv_splits,\n",
    "             metric_scores=metric_scores,\n",
    "             metric_labels=metric_labels,\n",
    "             y_predictions=y_predictions,\n",
    "             y_scores=y_scores,\n",
    "             best_params_lin=best_params_lin,\n",
    "             dtype=object\n",
    "            )\n",
    "    \n",
    "    # Save results summary to DataFrame for quick overview\n",
    "    results_df = pd.DataFrame([metric_scores.mean(axis=0)], columns=metric_labels)\n",
    "    results_df.to_csv(os.path.join(save_dir, 'clf_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLF_RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16517d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse clasification performances without permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_paths = np.array(sorted(glob(os.path.join(CLF_RESULTS_DIR, '*', '*', 'clf_results.npz'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics_to_report = ['AUC', 'balanced_accuracy', 'sensitivity', 'specificity', \n",
    "                         'positive_predictive_value', 'negative_predictive_value']\n",
    "\n",
    "pooled_results_columns = np.append(['analysis_label', 'filter_str', 'age_group', 'feature_set'], \n",
    "                                   clf_metrics_to_report)\n",
    "pooled_results_df = pd.DataFrame(columns=pooled_results_columns)\n",
    "\n",
    "for result_path in result_paths:\n",
    "    \n",
    "    result_dir = os.path.dirname(result_path)\n",
    "    \n",
    "    analysis_label = result_dir.split('/')[-2]\n",
    "    clf_title = os.path.basename(result_dir)\n",
    "    \n",
    "    clf_task = clf_title.split('_CLF_')[0]\n",
    "    age_group = clf_title.split('_CLF_')[1].split('_SAMPLES_')[0]\n",
    "    feature_set = clf_title.split('_CLF_')[1].split('_SAMPLES_')[1].split('_FEATURES')[0]\n",
    "\n",
    "    filter_string = clf_title.split('_FEATURES_')[1].split('_FILTER')[0] if '_FILTER' in clf_title else ''\n",
    "    \n",
    "    # Load neutral permutation (actual obtained classification result)\n",
    "    clf_result = os.path.join(result_dir, 'clf_results.npz')\n",
    "    clf_metrics = np.load(clf_result, allow_pickle=True)['metric_scores']\n",
    "    metric_labels = np.load(clf_result, allow_pickle=True)['metric_labels']\n",
    "    \n",
    "    # Sanity check here!\n",
    "    results_df = pd.read_csv(os.path.join(result_dir, 'clf_summary.csv'))\n",
    "    \n",
    "    assert np.isclose(results_df.AUC.values[0], clf_metrics[:, metric_labels=='AUC'].mean())\n",
    "    \n",
    "    # Extract N used for classification to compute confidence intervals\n",
    "    N = np.load(clf_result, allow_pickle=True)['y_predictions'].shape[-1]\n",
    "    \n",
    "    clf_metrics_formatted = [np.round(clf_metrics[:, metric_labels==l].mean(), 3) for l in clf_metrics_to_report]\n",
    "\n",
    "    tmp_df = pd.DataFrame(columns=pooled_results_columns,\n",
    "                          data=np.c_[[analysis_label], [filter_string], [age_group], [feature_set],  \n",
    "                                     [clf_metrics_formatted]])\n",
    "\n",
    "    pooled_results_df = pd.concat([pooled_results_df, tmp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'clf_results_wo_perms_' + datetime.date.today().strftime(\"%d_%m_%Y\") + '.csv'\n",
    "pooled_results_df.to_csv(os.path.join(CLF_RESULTS_DIR, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENIGMA_OCD_RSFMRI",
   "language": "python",
   "name": "enigma_ocd_rsfmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
